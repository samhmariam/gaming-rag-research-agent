{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libs\n",
    "\n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrieve_game tool\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    You'll receive results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the persistent Chroma database used in Part 01\n",
    "        chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "        # Ensure we use the same embedding function configuration as when the collection was created\n",
    "        embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=OPENAI_API_KEY\n",
    "        )\n",
    "\n",
    "        # Get the existing collection\n",
    "        collection = chroma_client.get_collection(\n",
    "            name=\"udaplay\",\n",
    "            embedding_function=embedding_fn\n",
    "        )\n",
    "\n",
    "        # Perform semantic search over stored documents\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=5,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "        )\n",
    "\n",
    "        formatted_results = []\n",
    "        docs = results.get(\"documents\") or []\n",
    "        metas = results.get(\"metadatas\") or []\n",
    "        dists = results.get(\"distances\") or []\n",
    "\n",
    "        if docs and len(docs) > 0:\n",
    "            for i, doc in enumerate(docs[0]):\n",
    "                meta = metas[0][i] if metas and metas[0] and i < len(metas[0]) else {}\n",
    "                dist = dists[0][i] if dists and dists[0] and i < len(dists[0]) else None\n",
    "\n",
    "                description = meta.get(\"Description\") or doc\n",
    "                formatted_results.append({\n",
    "                    \"Platform\": meta.get(\"Platform\", \"Unknown\"),\n",
    "                    \"Name\": meta.get(\"Name\", \"Unknown\"),\n",
    "                    \"YearOfRelease\": meta.get(\"YearOfRelease\", \"Unknown\"),\n",
    "                    \"Description\": description,\n",
    "                    # Optional: include a relevance hint for downstream evaluation\n",
    "                    \"Relevance_Score\": f\"{1 - dist:.3f}\" if isinstance(dist, (int, float)) else \"Unknown\",\n",
    "                })\n",
    "\n",
    "        return str(formatted_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return a plain string to keep tool outputs simple for the agent\n",
    "        return str([\n",
    "            {\n",
    "                \"error\": \"Failed to retrieve from vector DB\",\n",
    "                \"details\": str(e),\n",
    "            }\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8739d2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\\'Platform\\': \\'Game Boy Color\\', \\'Name\\': \\'Pokémon Gold and Silver\\', \\'YearOfRelease\\': 1999, \\'Description\\': \\'Second-generation Pokémon games introducing new regions, Pokémon, and gameplay mechanics.\\', \\'Relevance_Score\\': \\'0.774\\'}, {\\'Platform\\': \\'Game Boy Advance\\', \\'Name\\': \\'Pokémon Ruby and Sapphire\\', \\'YearOfRelease\\': 2002, \\'Description\\': \\'Third-generation Pokémon games set in the Hoenn region, featuring new Pokémon and double battles.\\', \\'Relevance_Score\\': \\'0.708\\'}, {\\'Platform\\': \\'Nintendo 64\\', \\'Name\\': \\'Super Mario 64\\', \\'YearOfRelease\\': 1996, \\'Description\\': \"A groundbreaking 3D platformer that set new standards for the genre, featuring Mario\\'s quest to rescue Princess Peach.\", \\'Relevance_Score\\': \\'0.544\\'}, {\\'Platform\\': \\'Super Nintendo Entertainment System (SNES)\\', \\'Name\\': \\'Super Mario World\\', \\'YearOfRelease\\': 1990, \\'Description\\': \\'A classic platformer where Mario embarks on a quest to save Princess Toadstool and Dinosaur Land from Bowser.\\', \\'Relevance_Score\\': \\'0.532\\'}, {\\'Platform\\': \\'Nintendo Switch\\', \\'Name\\': \\'Mario Kart 8 Deluxe\\', \\'YearOfRelease\\': 2017, \\'Description\\': \\'An enhanced version of Mario Kart 8, featuring new characters, tracks, and improved gameplay mechanics.\\', \\'Relevance_Score\\': \\'0.517\\'}]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_game(\"When were Pokémon Gold and Silver released?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b679029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\\'Platform\\': \\'Nintendo 64\\', \\'Name\\': \\'Super Mario 64\\', \\'YearOfRelease\\': 1996, \\'Description\\': \"A groundbreaking 3D platformer that set new standards for the genre, featuring Mario\\'s quest to rescue Princess Peach.\", \\'Relevance_Score\\': \\'0.782\\'}, {\\'Platform\\': \\'Super Nintendo Entertainment System (SNES)\\', \\'Name\\': \\'Super Mario World\\', \\'YearOfRelease\\': 1990, \\'Description\\': \\'A classic platformer where Mario embarks on a quest to save Princess Toadstool and Dinosaur Land from Bowser.\\', \\'Relevance_Score\\': \\'0.727\\'}, {\\'Platform\\': \\'Nintendo Switch\\', \\'Name\\': \\'Mario Kart 8 Deluxe\\', \\'YearOfRelease\\': 2017, \\'Description\\': \\'An enhanced version of Mario Kart 8, featuring new characters, tracks, and improved gameplay mechanics.\\', \\'Relevance_Score\\': \\'0.603\\'}, {\\'Platform\\': \\'GameCube\\', \\'Name\\': \\'Super Smash Bros. Melee\\', \\'YearOfRelease\\': 2001, \\'Description\\': \\'A crossover fighting game featuring characters from various Nintendo franchises battling it out in dynamic arenas.\\', \\'Relevance_Score\\': \\'0.595\\'}, {\\'Platform\\': \\'Game Boy Color\\', \\'Name\\': \\'Pokémon Gold and Silver\\', \\'YearOfRelease\\': 1999, \\'Description\\': \\'Second-generation Pokémon games introducing new regions, Pokémon, and gameplay mechanics.\\', \\'Relevance_Score\\': \\'0.563\\'}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_game(\"Which was the first 3D platformer Mario game?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluate_retrieval tool\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from lib.parsers import PydanticOutputParser\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    \"\"\"Evaluation report for retrieved documents\"\"\"\n",
    "    useful: bool = Field(description=\"Whether the documents are useful to answer the question\")\n",
    "    description: str = Field(description=\"Detailed explanation about the evaluation result\")\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: str) -> str:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents,\n",
    "    it will analyze the usability of the documents to respond to that question.\n",
    "    args:\n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize LLM for evaluation\n",
    "        llm = LLM(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "        # Build an instruction-focused evaluation prompt\n",
    "        evaluation_prompt = f\"\"\"\n",
    "        Your task is to evaluate if the documents are enough to respond the query.\n",
    "        Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "\n",
    "        Evaluation criteria:\n",
    "        - Relevance: Do the documents relate directly to the question?\n",
    "        - Sufficiency: Is there enough detail to confidently answer?\n",
    "        - Specificity: Are key details present (e.g., dates, platforms, names)?\n",
    "        - Consistency: Do the documents agree or conflict?\n",
    "\n",
    "        User Question:\n",
    "        {question}\n",
    "\n",
    "        Retrieved Documents (list of dicts or text):\n",
    "        {retrieved_docs}\n",
    "\n",
    "        Respond with JSON containing fields: useful (bool), description (string)\n",
    "        \"\"\"\n",
    "\n",
    "        # Ask LLM to produce a structured response\n",
    "        response = llm.invoke(\n",
    "            input=evaluation_prompt,\n",
    "            response_format=EvaluationReport,\n",
    "        )\n",
    "\n",
    "        # Parse the structured response\n",
    "        parser = PydanticOutputParser(model_class=EvaluationReport)\n",
    "        evaluation = parser.parse(response)\n",
    "\n",
    "        return f\"Useful: {evaluation.useful}, Description: {evaluation.description}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback heuristic if LLM or parsing fails\n",
    "        docs_text = str(retrieved_docs).lower()\n",
    "        question_text = question.lower()\n",
    "\n",
    "        key_terms = [w for w in question_text.replace(\"?\", \"\").split() if len(w) > 3]\n",
    "        matches = sum(1 for term in key_terms if term in docs_text)\n",
    "\n",
    "        useful = matches > 0 and len(docs_text) > 50\n",
    "        description = (\n",
    "            f\"Fallback evaluation: Found {matches} matching key terms in retrieved docs. \"\n",
    "            f\"Original error: {str(e)}\"\n",
    "        )\n",
    "        return f\"Useful: {useful}, Description: {description}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113cdc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Useful: True, Description: The retrieved documents contain relevant information regarding the release of Pokémon Gold and Silver. Specifically, one document directly addresses the user question by stating that Pokémon Gold and Silver were released in 1999 on the Game Boy Color. This document is highly relevant, as it provides the exact name of the game, the platform it was released on, and the year of release, which are all key details necessary to answer the question confidently. \\n\\nThe other documents retrieved discuss different Pokémon games and platforms, but they do not pertain to the user's question about Pokémon Gold and Silver. However, since the first document provides a clear and direct answer, the overall evaluation is that the documents are sufficient to respond to the query. \\n\\nIn summary, the relevant document provides the necessary details (name, platform, year) and there are no conflicting details present, making the information consistent and reliable.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test: retrieve and evaluate\n",
    "query = \"When was Pokémon Gold and Silver released?\"\n",
    "retrieved = retrieve_game(query)\n",
    "evaluate_retrieval(query, retrieved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create game_web_search tool\n",
    "\n",
    "from tavily import TavilyClient\n",
    "\n",
    "@tool\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Web search: Searches the internet for information about the gaming industry\n",
    "    args:\n",
    "    - question: a question about game industry.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "        # Bias the query toward gaming context\n",
    "        query = f\"video games gaming industry: {question}\"\n",
    "        results = client.search(\n",
    "            query=query,\n",
    "            search_depth=\"advanced\",\n",
    "            max_results=5,\n",
    "            include_answer=True,\n",
    "            include_raw_content=False,\n",
    "        )\n",
    "\n",
    "        formatted = []\n",
    "        if isinstance(results, dict):\n",
    "            if results.get(\"answer\"):\n",
    "                formatted.append({\"Summary\": results[\"answer\"]})\n",
    "            for i, item in enumerate((results.get(\"results\") or [])[:5], start=1):\n",
    "                formatted.append({\n",
    "                    \"Title\": item.get(\"title\", \"\"),\n",
    "                    \"URL\": item.get(\"url\", \"\"),\n",
    "                    \"Content\": item.get(\"content\", \"\"),\n",
    "                    \"Score\": item.get(\"score\", 0),\n",
    "                })\n",
    "        else:\n",
    "            formatted.append({\"info\": \"Unexpected response shape from Tavily\"})\n",
    "\n",
    "        return str(formatted) if formatted else \"[]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return str([\n",
    "            {\n",
    "                \"error\": \"Web search failed\",\n",
    "                \"details\": str(e),\n",
    "                \"hint\": \"Check TAVILY_API_KEY and network connectivity\",\n",
    "            }\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e06759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\\'Summary\\': \\'Metroid Prime 4: Beyond is set for release on December 4, 2025. It will be available on Nintendo Switch and Switch 2.\\'}, {\\'Title\\': \\'Metroid Prime 4: Beyond gets a new trailer and a December release ...\\', \\'URL\\': \\'https://nintendowire.com/news/2025/09/17/metroid-prime-4-beyond-gets-a-new-trailer-and-a-december-release-date/\\', \\'Content\\': \\'Of course, that wasn’t all that was shown off here. Among the rest of the gameplay footage and a brief new look at the returning Sylux, we got some exciting release date news. Metroid Prime 4: Beyond is set for release on both Nintendo Switch and Nintendo Switch 2 on December 4th, 2025. In addition, an artbook for the game is coming out on October 28th. That’s not even the end of it though, as to wrap it all up we got confirmation of three new amiibo for the game to release alongside it! [...] For all of those out there who have been eagerly awaiting the release of Metroid Prime 4, it’s finally almost here. Now with a known release date and even more to look forward to thanks to today’s trailer, the excitement has truly hit a new level. Mark your calendars for December 4th, get in those pre-orders, and get ready to join Samus in her latest adventure through the world of Viewros!\\\\n\\\\nMore news from the September 2025 Direct [...] Of the many different video game genres out there, one that keeps bringing people together time and time again are the beloved cozy games. From staples like Animal Crossing and indie hits like Stardew Valley and so many more, the formula is seeing more success than ever before. That goes…\\\\n\\\\nRead More\\\\n\\\\nSeptember 17th, 2025\\', \\'Score\\': 0.86136365}, {\\'Title\\': \\'Metroid Prime 4: Beyond\\', \\'URL\\': \\'https://en.wikipedia.org/wiki/Metroid_Prime_4:_Beyond\\', \\'Content\\': \"Nintendo announced Metroid Prime 4 at E3 2017. It was reportedly initially developed by Bandai Namco Studios with Kensuke Tanabe, the producer of the previous Metroid Prime games. In 2019, unhappy with progress, Nintendo announced that development had restarted with Tanabe under Retro Studios, the developer of the previous Metroid Prime games. In June 2024, they announced the title Beyond and released the first trailer. Beyond is scheduled for release on December 4, 2025.\\\\n\\\\n## Premise\\\\n\\\\n[edit] [...] Nintendo released the first trailer and the title Metroid Prime 4: Beyond on June 18, 2024. It showcased similar gameplay to previous Metroid Prime games, with Samus exiting her gunship, exploring a forest world, using her morph ball ability, scanning a Space Pirate and encountering the bounty hunter Sylux, who first appeared in Metroid Prime Hunters. Nintendo also announced that Metroid Prime 4: Beyond is scheduled for release in 2025. It was nominated for Most Anticipated Game at the Game [...] showcasing a desert environment and Samus\\'s motorcycle and announced the release date, December 4. Amiibo figures were also announced.\", \\'Score\\': 0.8124067}, {\\'Title\\': \\'Metroid Prime 4: Beyond Finally Has a Release Date, While Samus ...\\', \\'URL\\': \\'https://www.ign.com/articles/metroid-prime-4-beyond-finally-has-a-release-date-while-samus-has-a-motorbike\\', \\'Content\\': \"Metroid Prime 4Metroid Prime 4: Beyond - Nintendo Switch 2 Edition\\\\n\\\\n# Metroid Prime 4: Beyond Finally Has a Release Date, While Samus Has a Motorbike\\\\n\\\\n## Rolling out.\\\\n\\\\nNearly a decade on from its initial announcement, Nintendo will finally launch Metroid Prime 4: Beyond for Switch and Switch 2 later this year, on December 4, 2025. [...] Development on the project initially began at Bandai Namco Studios, though Nintendo rebooted the game back at Metroid Prime trilogy developer Retro Studios after two years, unhappy with how development had unfolded. Little was then heard of the game for years, until it was formally re-announced in 2024, and then confirmed as a cross-gen title for Switch and Switch 2. [...] Nintendo made the announcement today during its major Nintendo Direct broadcast, ending months of speculation around Metroid Prime 4\\'s whereabouts. Nothing had been seen of the game since the Switch 2\\'s big reveal event back at the start of April, something that had prompted fan speculation the game had run into difficulty, or was set to be delayed again.\", \\'Score\\': 0.75355774}, {\\'Title\\': \\'Metroid Prime 4: Beyond – Nintendo Direct 9.12.2025 - YouTube\\', \\'URL\\': \\'https://www.youtube.com/watch?v=kJNCNswbdG0\\', \\'Content\\': \\'# Metroid Prime 4: Beyond – Nintendo Direct 9.12.2025\\\\n\\\\nNintendo of America\\\\n23081 likes\\\\n596874 views\\\\n12 Sep 2025\\\\nMetroid Prime 4: Beyond releases for Nintendo Switch and Nintendo Switch 2 on Dec 4, 2025. Pre-order today: [...] Visit Nintendo.com for more info: \\\\n\\\\nSubscribe for more Nintendo fun: \\\\n\\\\nFollow Nintendo of America\\\\nX/Twitter: \\\\nFacebook: \\\\nInstagram: \\\\nTwitch: \\\\n5192 comments [...] Samus is targeted by the deadly sharpshooter Sylux, and lands on Viewros in the aftermath of their clash. She’ll need all her tools and abilities, including her new technologically-advanced bike Vi-O-La, to survive and escape.\\\\n \\\\nAdditionally, three new Metroid Prime 4: Beyond amiibo are also on the way: Samus (Metroid Prime 4), Samus & Vi-O-La (Metroid Prime 4), and enigmatic bounty hunter Sylux (Metroid Prime 4). \\\\n\\\\n#MetroidPrime4 #NintendoSwitch2 #NintendoSwitch #NintendoDirect\\', \\'Score\\': 0.7311551}, {\\'Title\\': \\'Metroid Prime™ 4: Beyond for Nintendo Switch - Nintendo Official Site\\', \\'URL\\': \\'https://www.nintendo.com/us/store/products/metroid-prime-4-beyond-switch/?srsltid=AfmBOops6Gzcdv4FcCnS_VpLZuDPdrX8KTad9g0f6zz_j4IxaHchru6R\\', \\'Content\\': \\'Release date. December 4, 2025. ESRB rating. Animated Blood, Violence. In-Game Purchases. About Supported Features. This software supports the following\\', \\'Score\\': 0.6664756}]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test: web search fallback\n",
    "# Example: a question likely requiring web info\n",
    "game_web_search(\"What is the release date of Metroid Prime 4?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c56281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UdaPlay Agent created! Model: gpt-4o-mini\n",
      "Tools: retrieve_game, evaluate_retrieval, game_web_search\n"
     ]
    }
   ],
   "source": [
    "# Create your Agent abstraction using StateMachine\n",
    "\n",
    "# Instantiate the UdaPlay Research Agent\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    instructions=\"\"\"\n",
    "You are UdaPlay, an AI Research Agent for the video game industry.\n",
    "\n",
    "Capabilities:\n",
    "1. Answer questions using internal knowledge from the gaming database (RAG)\n",
    "2. When internal info is insufficient, search the web\n",
    "3. Maintain conversation state across turns\n",
    "4. Return structured, clear, and accurate outputs\n",
    "5. Be transparent about sources and uncertainty\n",
    "\n",
    "Workflow:\n",
    "1. First use the tool `retrieve_game` to search the internal vector database\n",
    "2. Use `evaluate_retrieval` to decide if the retrieved info is sufficient\n",
    "3. If not sufficient, use `game_web_search` to gather more info\n",
    "4. Synthesize a final answer, citing where information came from (internal DB and/or web)\n",
    "\n",
    "Guidelines:\n",
    "- Be precise and factual: include relevant details like release dates and platforms\n",
    "- Prefer evidence over speculation; when unsure, explicitly indicate uncertainty\n",
    "- Keep answers concise but complete; use bullet points when useful\n",
    "- Never fabricate citations; only cite the sources you truly used\n",
    "\"\"\",\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    ")\n",
    "\n",
    "print(\"UdaPlay Agent created! Model:\", udaplay_agent.model_name)\n",
    "print(\"Tools:\", \", \".join(t.name for t in udaplay_agent.tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UdaPlay Agent Quick Run ===\n",
      "\n",
      "Q1: When was Pokémon Gold and Silver released?\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer:\n",
      "Pokémon Gold and Silver were released in **1999** for the **Game Boy Color**. These games introduced the second generation of Pokémon, along with new regions and gameplay mechanics.\n",
      "------------------------------------------------------------\n",
      "Q2: Which one was the first 3D platformer Mario game?\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, released in **1996** for the **Nintendo 64**. This game was groundbreaking and set new standards for the genre, featuring Mario's quest to rescue Princess Peach.\n",
      "------------------------------------------------------------\n",
      "Q3: Was Mortal Kombat X released for PlayStation 5?\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer:\n",
      "Mortal Kombat X was not released specifically for the PlayStation 5; however, it was released for the **PlayStation 4** on **April 14, 2015**, and it is playable on the PlayStation 5. While you can play it on PS5, some features that were available on the PS4 may be absent.\n",
      "------------------------------------------------------------\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Invoke your agent on sample questions\n",
    "\n",
    "print(\"=== UdaPlay Agent Quick Run ===\\n\")\n",
    "\n",
    "samples = [\n",
    "    \"When was Pokémon Gold and Silver released?\",\n",
    "    \"Which one was the first 3D platformer Mario game?\",\n",
    "    \"Was Mortal Kombat X released for PlayStation 5?\",\n",
    "]\n",
    "\n",
    "for i, q in enumerate(samples, 1):\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    try:\n",
    "        run = udaplay_agent.invoke(q)\n",
    "        final_state = run.get_final_state()\n",
    "        if final_state and final_state.get(\"messages\"):\n",
    "            ai_msgs = [m for m in final_state[\"messages\"] if hasattr(m, 'content') and m.content]\n",
    "            if ai_msgs:\n",
    "                print(\"Answer:\")\n",
    "                print(ai_msgs[-1].content)\n",
    "            else:\n",
    "                print(\"No AI message content available.\")\n",
    "        else:\n",
    "            print(\"No final state/messages.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool retrieve_game_ltm is properly configured\n",
      "Tool evaluate_retrieval_ltm is properly configured\n",
      "Tool game_web_search_ltm is properly configured\n",
      "Tool recall_memory_ltm is properly configured\n",
      "Tool save_memory_ltm is properly configured\n",
      "UdaPlay Agent v2 created with 5 tools\n",
      "Explicit Research StateMachine constructed with tool nodes.\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: recall_memory\n",
      "[StateMachine] Executing step: retrieve_game\n",
      "[StateMachine] Executing step: evaluate_retrieval\n",
      "[StateMachine] Executing step: synthesize_answer\n",
      "[StateMachine] Executing step: store_answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      " Pokémon Gold and Silver were released in 1999 for the Game Boy Color. This information is sourced from the internal database.\n"
     ]
    }
   ],
   "source": [
    "# Advanced: Long-Term Memory + Explicit State Machine with Tool Nodes\n",
    "\n",
    "from typing import TypedDict, Optional, Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "from lib.memory import LongTermMemory, MemoryFragment, TimestampFilter\n",
    "from lib.vector_db import VectorStoreManager\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination\n",
    "from lib.llm import LLM\n",
    "from lib.tooling import Tool, tool\n",
    "\n",
    "# 1) Initialize Long-Term Memory (LTM)\n",
    "#    Uses OpenAI embeddings via VectorStoreManager; persists inside a Chroma collection.\n",
    "vector_manager = VectorStoreManager(OPENAI_API_KEY)\n",
    "long_memory = LongTermMemory(vector_manager)\n",
    "\n",
    "# 2) Create memory functions that will be wrapped as tools\n",
    "@tool\n",
    "def save_memory_ltm(owner: str, content: str, namespace: str = \"default\") -> str:\n",
    "    \"\"\"\n",
    "    Save a memory fragment for a given `owner` into long-term memory.\n",
    "    args:\n",
    "    - owner: user id or session id\n",
    "    - content: the fact/preference/answer to retain\n",
    "    - namespace: logical grouping of memories\n",
    "    \"\"\"\n",
    "    try:\n",
    "        long_memory.register(\n",
    "            MemoryFragment(content=content, owner=owner, namespace=namespace)\n",
    "        )\n",
    "        return json.dumps({\"status\": \"ok\", \"saved\": True})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"status\": \"error\", \"message\": str(e)})\n",
    "\n",
    "@tool\n",
    "def recall_memory_ltm(owner: str, query: str, namespace: str = \"default\", limit: int = 3, within_hours: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Recall relevant memories for `owner` semantically similar to `query`.\n",
    "    args:\n",
    "    - owner: user id or session id\n",
    "    - query: search text to match memories\n",
    "    - namespace: filter namespace\n",
    "    - limit: number of memories to return\n",
    "    - within_hours: if provided, only return memories newer than now - within_hours\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ts_filter = None\n",
    "        if within_hours is not None:\n",
    "            cutoff = int((datetime.now() - timedelta(hours=within_hours)).timestamp())\n",
    "            ts_filter = TimestampFilter(greater_than_value=cutoff)\n",
    "        result = long_memory.search(query_text=query, owner=owner, limit=limit, timestamp_filter=ts_filter, namespace=namespace)\n",
    "        out = []\n",
    "        for frag, dist in zip(result.fragments, result.metadata.get(\"distances\", [])):\n",
    "            out.append({\n",
    "                \"content\": frag.content,\n",
    "                \"owner\": frag.owner,\n",
    "                \"namespace\": frag.namespace,\n",
    "                \"timestamp\": frag.timestamp,\n",
    "                \"distance\": dist,\n",
    "            })\n",
    "        return json.dumps(out, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"status\": \"error\", \"message\": str(e)})\n",
    "\n",
    "# 3) Create other tool functions that we'll use directly in StateMachine\n",
    "\n",
    "@tool\n",
    "def retrieve_game_ltm(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import chromadb\n",
    "        from chromadb.utils import embedding_functions\n",
    "        \n",
    "        chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "        embedding_fn = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY)\n",
    "        collection = chroma_client.get_collection(name=\"udaplay\", embedding_function=embedding_fn)\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=5,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "        )\n",
    "        formatted_results = []\n",
    "        docs = results.get(\"documents\") or []\n",
    "        metas = results.get(\"metadatas\") or []\n",
    "        dists = results.get(\"distances\") or []\n",
    "        if docs and len(docs) > 0:\n",
    "            for i, doc in enumerate(docs[0]):\n",
    "                meta = metas[0][i] if metas and metas[0] and i < len(metas[0]) else {}\n",
    "                dist = dists[0][i] if dists and dists[0] and i < len(dists[0]) else None\n",
    "                description = meta.get(\"Description\") or doc\n",
    "                formatted_results.append({\n",
    "                    \"Platform\": meta.get(\"Platform\", \"Unknown\"),\n",
    "                    \"Name\": meta.get(\"Name\", \"Unknown\"),\n",
    "                    \"YearOfRelease\": meta.get(\"YearOfRelease\", \"Unknown\"),\n",
    "                    \"Description\": description,\n",
    "                    \"Relevance_Score\": f\"{1 - dist:.3f}\" if isinstance(dist, (int, float)) else \"Unknown\",\n",
    "                })\n",
    "        return str(formatted_results)\n",
    "    except Exception as e:\n",
    "        return str([{ \"error\": \"Failed to retrieve from vector DB\", \"details\": str(e) }])\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval_ltm(question: str, retrieved_docs: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate if retrieved documents are useful for answering the question\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pydantic import BaseModel, Field\n",
    "        from lib.parsers import PydanticOutputParser\n",
    "\n",
    "        class EvaluationReport(BaseModel):\n",
    "            useful: bool = Field(description=\"Whether the documents are useful to answer the question\")\n",
    "            description: str = Field(description=\"Detailed explanation about the evaluation result\")\n",
    "\n",
    "        llm = LLM(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "        evaluation_prompt = f\"\"\"\n",
    "Your task is to evaluate if the documents are enough to respond the query.\n",
    "Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "\n",
    "Evaluation criteria:\n",
    "- Relevance: Do the documents relate directly to the question?\n",
    "- Sufficiency: Is there enough detail to confidently answer?\n",
    "- Specificity: Are key details present (e.g., dates, platforms, names)?\n",
    "- Consistency: Do the documents agree or conflict?\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Retrieved Documents (list of dicts or text):\n",
    "{retrieved_docs}\n",
    "\n",
    "Respond with JSON containing fields: useful (bool), description (string)\n",
    "\"\"\"\n",
    "        response = llm.invoke(input=evaluation_prompt, response_format=EvaluationReport)\n",
    "        parser = PydanticOutputParser(model_class=EvaluationReport)\n",
    "        evaluation = parser.parse(response)\n",
    "        return f\"Useful: {evaluation.useful}, Description: {evaluation.description}\"\n",
    "    except Exception as e:\n",
    "        docs_text = str(retrieved_docs).lower()\n",
    "        question_text = question.lower()\n",
    "        key_terms = [w for w in question_text.replace(\"?\", \"\").split() if len(w) > 3]\n",
    "        matches = sum(1 for term in key_terms if term in docs_text)\n",
    "        useful = matches > 0 and len(docs_text) > 50\n",
    "        description = (\n",
    "            f\"Fallback evaluation: Found {matches} matching key terms in retrieved docs. Original error: {str(e)}\"\n",
    "        )\n",
    "        return f\"Useful: {useful}, Description: {description}\"\n",
    "\n",
    "@tool\n",
    "def game_web_search_ltm(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Web search for gaming industry information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from tavily import TavilyClient\n",
    "        \n",
    "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "        query = f\"video games gaming industry: {question}\"\n",
    "        results = client.search(\n",
    "            query=query,\n",
    "            search_depth=\"advanced\",\n",
    "            max_results=5,\n",
    "            include_answer=True,\n",
    "            include_raw_content=False,\n",
    "        )\n",
    "        formatted = []\n",
    "        if isinstance(results, dict):\n",
    "            if results.get(\"answer\"):\n",
    "                formatted.append({\"Summary\": results[\"answer\"]})\n",
    "            for i, item in enumerate((results.get(\"results\") or [])[:5], start=1):\n",
    "                formatted.append({\n",
    "                    \"Title\": item.get(\"title\", \"\"),\n",
    "                    \"URL\": item.get(\"url\", \"\"),\n",
    "                    \"Content\": item.get(\"content\", \"\"),\n",
    "                    \"Score\": item.get(\"score\", 0),\n",
    "                })\n",
    "        else:\n",
    "            formatted.append({\"info\": \"Unexpected response shape from Tavily\"})\n",
    "        return str(formatted) if formatted else \"[]\"\n",
    "    except Exception as e:\n",
    "        return str([{ \"error\": \"Web search failed\", \"details\": str(e), \"hint\": \"Check TAVILY_API_KEY and network connectivity\" }])\n",
    "\n",
    "# Verify all tools have proper names\n",
    "tools_for_agent = [retrieve_game_ltm, evaluate_retrieval_ltm, game_web_search_ltm, recall_memory_ltm, save_memory_ltm]\n",
    "for t in tools_for_agent:\n",
    "    if not hasattr(t, 'name') or not t.name:\n",
    "        print(f\"Warning: Tool {t} doesn't have a proper name\")\n",
    "    else:\n",
    "        print(f\"Tool {t.name} is properly configured\")\n",
    "\n",
    "# 4) Update the Agent to include long-term memory tools (v2)\n",
    "udaplay_agent_v2 = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    instructions=\n",
    "    \"\"\"\n",
    "You are UdaPlay, an AI Research Agent for the video game industry.\n",
    "In addition to RAG and web search, you can save and recall useful user memories.\n",
    "When you reach a confident and useful answer, store a brief fact using the `save_memory_ltm` tool.\n",
    "Before answering questions, try to use `recall_memory_ltm` to retrieve relevant context.\n",
    "    \"\"\".strip(),\n",
    "    tools=tools_for_agent,\n",
    ")\n",
    "\n",
    "print(f\"UdaPlay Agent v2 created with {len(udaplay_agent_v2.tools)} tools\")\n",
    "\n",
    "# 5) Build an explicit StateMachine where tools are predefined nodes\n",
    "\n",
    "# State schema for the explicit research workflow\n",
    "class ResearchState(TypedDict, total=False):\n",
    "    question: str\n",
    "    owner: str\n",
    "    session_id: str\n",
    "    memory_results: str\n",
    "    retrieved_docs: str\n",
    "    retrieval_useful: bool\n",
    "    evaluation_notes: str\n",
    "    web_results: str\n",
    "    final_answer: str\n",
    "\n",
    "# Helper: parse the evaluate_retrieval string result\n",
    "\n",
    "def _parse_evaluation(text: str) -> Dict[str, Optional[str]]:\n",
    "    # Expected like: \"Useful: True, Description: ...\"\n",
    "    useful = None\n",
    "    description = None\n",
    "    try:\n",
    "        lower = text.strip()\n",
    "        parts = lower.split(\",\", 1)\n",
    "        if parts:\n",
    "            if \"true\" in parts[0].lower():\n",
    "                useful = True\n",
    "            elif \"false\" in parts[0].lower():\n",
    "                useful = False\n",
    "        if len(parts) > 1:\n",
    "            desc = parts[1].strip()\n",
    "            if desc.lower().startswith(\"description:\"):\n",
    "                desc = desc[len(\"description:\"):].strip()\n",
    "            description = desc\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\"useful\": useful, \"description\": description}\n",
    "\n",
    "# Steps definitions - Now using the function directly\n",
    "\n",
    "# Recall memory step\n",
    "recall_step = Step[ResearchState](\n",
    "    \"recall_memory\",\n",
    "    lambda state: {\n",
    "        \"memory_results\": recall_memory_ltm.func(\n",
    "            owner=state.get(\"owner\", state.get(\"session_id\", \"default\")),\n",
    "            query=state[\"question\"],\n",
    "            namespace=\"default\",\n",
    "            limit=3,\n",
    "            within_hours=None,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Retrieve from internal DB step\n",
    "retrieve_step = Step[ResearchState](\n",
    "    \"retrieve_game\",\n",
    "    lambda state: {\n",
    "        \"retrieved_docs\": retrieve_game_ltm.func(query=state[\"question\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "# Evaluate retrieval utility step\n",
    "\n",
    "def _eval_logic(state: ResearchState) -> ResearchState:\n",
    "    raw = evaluate_retrieval_ltm.func(\n",
    "        question=state[\"question\"],\n",
    "        retrieved_docs=state.get(\"retrieved_docs\", \"\")\n",
    "    )\n",
    "    parsed = _parse_evaluation(raw)\n",
    "    return {\n",
    "        \"retrieval_useful\": bool(parsed.get(\"useful\", False)),\n",
    "        \"evaluation_notes\": parsed.get(\"description\", \"\")\n",
    "    }\n",
    "\n",
    "evaluate_step = Step[ResearchState](\"evaluate_retrieval\", _eval_logic)\n",
    "\n",
    "# Web search step (fallback)\n",
    "web_search_step = Step[ResearchState](\n",
    "    \"game_web_search\",\n",
    "    lambda state: {\n",
    "        \"web_results\": game_web_search_ltm.func(question=state[\"question\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "# Synthesis step via LLM\n",
    "\n",
    "def _synthesize_logic(state: ResearchState) -> ResearchState:\n",
    "    llm = LLM(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    context_blobs: List[str] = []\n",
    "    if state.get(\"memory_results\"):\n",
    "        context_blobs.append(f\"Recalled Memory: {state['memory_results']}\")\n",
    "    if state.get(\"retrieved_docs\"):\n",
    "        context_blobs.append(f\"Internal DB: {state['retrieved_docs']}\")\n",
    "    if state.get(\"web_results\"):\n",
    "        context_blobs.append(f\"Web: {state['web_results']}\")\n",
    "\n",
    "    context_str = \"\\n\\n\".join(context_blobs) if context_blobs else \"(no extra context)\"\n",
    "    prompt = f\"\"\"\n",
    "You are UdaPlay. Answer the gaming question using the provided context.\n",
    "- Cite whether the info came from internal DB, web, and/or memory.\n",
    "- Be precise; include dates/platforms where relevant.\n",
    "- If uncertain, say so.\n",
    "\n",
    "Question:\n",
    "{state['question']}\n",
    "\n",
    "Context:\n",
    "{context_str}\n",
    "\n",
    "Provide a clear, concise answer.\n",
    "\"\"\".strip()\n",
    "    ai = llm.invoke(prompt)\n",
    "    return {\"final_answer\": ai.content}\n",
    "\n",
    "synthesize_step = Step[ResearchState](\"synthesize_answer\", _synthesize_logic)\n",
    "\n",
    "# Store final answer into LTM step\n",
    "\n",
    "def _store_answer_logic(state: ResearchState) -> ResearchState:\n",
    "    owner = state.get(\"owner\", state.get(\"session_id\", \"default\"))\n",
    "    summary = f\"Q: {state['question']}\\nA: {state.get('final_answer','')}\"\n",
    "    _ = save_memory_ltm.func(owner=owner, content=summary, namespace=\"answers\")\n",
    "    return {}\n",
    "\n",
    "store_answer_step = Step[ResearchState](\"store_answer\", _store_answer_logic)\n",
    "\n",
    "# Build the machine and transitions\n",
    "research_machine = StateMachine[ResearchState](ResearchState)\n",
    "entry = EntryPoint[ResearchState]()\n",
    "term = Termination[ResearchState]()\n",
    "\n",
    "research_machine.add_steps([\n",
    "    entry,\n",
    "    recall_step,\n",
    "    retrieve_step,\n",
    "    evaluate_step,\n",
    "    web_search_step,\n",
    "    synthesize_step,\n",
    "    store_answer_step,\n",
    "    term,\n",
    "])\n",
    "\n",
    "# Flow: entry -> recall -> retrieve -> evaluate -> (useful? synthesize : web_search -> synthesize) -> store -> term\n",
    "research_machine.connect(entry, recall_step)\n",
    "research_machine.connect(recall_step, retrieve_step)\n",
    "research_machine.connect(retrieve_step, evaluate_step)\n",
    "\n",
    "# Branch based on evaluation\n",
    "\n",
    "def _route_after_eval(state: ResearchState):\n",
    "    return synthesize_step if state.get(\"retrieval_useful\") else web_search_step\n",
    "\n",
    "research_machine.connect(evaluate_step, [synthesize_step, web_search_step], _route_after_eval)\n",
    "# If web search happened, go to synthesize next\n",
    "research_machine.connect(web_search_step, synthesize_step)\n",
    "# After synthesize, store answer, then terminate\n",
    "research_machine.connect(synthesize_step, store_answer_step)\n",
    "research_machine.connect(store_answer_step, term)\n",
    "\n",
    "print(\"Explicit Research StateMachine constructed with tool nodes.\")\n",
    "\n",
    "# 6) Quick demo run (single question). Feel free to adapt/loop as needed.\n",
    "owner_id = \"default_user\"\n",
    "question = \"When was Pokémon Gold and Silver released?\"\n",
    "run = research_machine.run({\n",
    "    \"question\": question,\n",
    "    \"owner\": owner_id,\n",
    "    \"session_id\": \"default\",\n",
    "})\n",
    "final_state = run.get_final_state()\n",
    "print(\"Final Answer:\\n\", (final_state or {}).get(\"final_answer\", \"<no answer>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7baed34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing UdaPlay Agent v2 with Memory ===\n",
      "\n",
      "Q1: When was Pokémon Gold and Silver released?\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer:\n",
      "Pokémon Gold and Silver were released in Japan on **November 21, 1999**, in North America on **October 15, 2000**, and in Europe on **April 6, 2001**. \n",
      "\n",
      "Would you like to learn more about these games or any specific features?\n",
      "------------------------------------------------------------\n",
      "Q2: What do you remember about Pokémon games?\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer:\n",
      "I still don't have any specific memories about Pokémon games stored. However, I can share general information or answer questions you may have about the series, its gameplay, different titles, or any other related topics. Just let me know what you're curious about!\n",
      "------------------------------------------------------------\n",
      "Done.\n",
      "\n",
      "=== Testing Explicit StateMachine with Web Search Fallback ===\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: recall_memory\n",
      "[StateMachine] Executing step: retrieve_game\n",
      "[StateMachine] Executing step: evaluate_retrieval\n",
      "[StateMachine] Executing step: game_web_search\n",
      "[StateMachine] Executing step: synthesize_answer\n",
      "[StateMachine] Executing step: store_answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Question: What is the latest information about Elden Ring DLC?\n",
      "Final Answer:\n",
      " The latest information about the Elden Ring DLC, titled \"Nightreign,\" indicates that it is set for release between October and December 2025. This DLC will feature new co-op survival gameplay and additional content, and it will be available on multiple platforms including PS5, Xbox Series X|S, PC, PS4, and Xbox One. The exact release date has not been specified yet. \n",
      "\n",
      "This information was sourced from web content, including YouTube videos and articles discussing the DLC.\n",
      "\n",
      "State Machine Execution Flow:\n",
      "- Memory Results: Found\n",
      "- Retrieved Docs: Found\n",
      "- Retrieval Useful: False\n",
      "- Web Results: Found\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced agent with memory capabilities and verify the StateMachine\n",
    "\n",
    "print(\"=== Testing UdaPlay Agent v2 with Memory ===\\n\")\n",
    "\n",
    "test_questions = [\n",
    "    \"When was Pokémon Gold and Silver released?\",\n",
    "    \"What do you remember about Pokémon games?\",  # This should recall the previous answer\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    try:\n",
    "        run = udaplay_agent_v2.invoke(q)\n",
    "        final_state = run.get_final_state()\n",
    "        if final_state and final_state.get(\"messages\"):\n",
    "            ai_msgs = [m for m in final_state[\"messages\"] if hasattr(m, 'content') and m.content]\n",
    "            if ai_msgs:\n",
    "                print(\"Answer:\")\n",
    "                print(ai_msgs[-1].content[:500] + \"...\" if len(ai_msgs[-1].content) > 500 else ai_msgs[-1].content)\n",
    "            else:\n",
    "                print(\"No AI message content available.\")\n",
    "        else:\n",
    "            print(\"No final state/messages.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# Test the explicit StateMachine with a different question\n",
    "print(\"=== Testing Explicit StateMachine with Web Search Fallback ===\\n\")\n",
    "\n",
    "# Ask about a game that might not be in our vector DB\n",
    "owner_id = \"test_user_2\"\n",
    "question = \"What is the latest information about Elden Ring DLC?\"\n",
    "run = research_machine.run({\n",
    "    \"question\": question,\n",
    "    \"owner\": owner_id,\n",
    "    \"session_id\": \"session_2\",\n",
    "})\n",
    "final_state = run.get_final_state()\n",
    "print(\"Question:\", question)\n",
    "print(\"Final Answer:\\n\", (final_state or {}).get(\"final_answer\", \"<no answer>\"))\n",
    "print(\"\\nState Machine Execution Flow:\")\n",
    "print(f\"- Memory Results: {'Found' if final_state.get('memory_results') else 'None'}\")\n",
    "print(f\"- Retrieved Docs: {'Found' if final_state.get('retrieved_docs') else 'None'}\")\n",
    "print(f\"- Retrieval Useful: {final_state.get('retrieval_useful', 'N/A')}\")\n",
    "print(f\"- Web Results: {'Found' if final_state.get('web_results') else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b1c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaming-rag-research-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
